name: Trigger Scrape Function Chain

on:
  push:
    branches: [ main ]
  schedule:
    - cron: '*/30 * * * *'

env:
  BASE_URL: "https://used-car-scraper-vercel.vercel.app/api/scrape"

jobs:
  scrape_pages:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        page: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
      max-parallel: 3  # Adjust this based on your needs and rate limits
    steps:
    - name: Scrape Page ${{ matrix.page }}
      run: |
        max_retries=3
        retry_count=0
        while [ $retry_count -lt $max_retries ]; do
          response=$(curl -s -w "\n%{http_code}" "${{ env.BASE_URL }}?page=${{ matrix.page }}")
          status_code=$(echo "$response" | tail -n1)
          body=$(echo "$response" | sed '$d')
          echo "Status code: $status_code"
          echo -e "Response body:\n$body"
          if [ $status_code -eq 200 ]; then
            echo "Scrape function for page ${{ matrix.page }} executed successfully"
            break
          else
            echo "Scrape function for page ${{ matrix.page }} failed with status code: $status_code"
            echo -e "Error details:\n$body"
            retry_count=$((retry_count+1))
            if [ $retry_count -lt $max_retries ]; then
              echo "Retrying in 5 seconds..."
              sleep 5
            else
              echo "Max retries reached. Exiting with failure."
              exit 1
            fi
          fi
        done